% intro.tex

%In this chapter we will present our findings and evaluate what impact the added features have on a working node.
In this chapter we will present the data we have collected from our measurements and how they were taken.

While management and monitoring can be both useful and convenient, it does introduce overhead. This overhead should not have a significant impact on system performance, others citing as low as 1-2\% impact as tolerable.

Here we will verify the impact of our work on the overall throughput and performance of the software under different workloads. We will look at requests processed per second and response time distribution under typical usage patterns and some edge cases. 

We will first look at single node performance, with and without our modifications.
Next we will try verifying that performance scaling is intact. For Voldemort, near linear scaling of throughput is expected when adding worker nodes to the cluster.
Lastly we will look at performance during a automatically triggered rebalance under load.

\section{The tests}
All tests are run on a clean cluster instance, with a warm up period loading data into the database. All tests are run three times, with the average score used.

Test0:

100\% read ?
100\% read no mod ?

99\% 1\% read/update ? read/write?
99\% 1\% read/update ? read/write? no mod

1\%/99\% read/write ?
1\%/99\% read/write ? no mod

linear scaling:
100\% read ? 2 nodes
100\% read no mod ? 2 nodes

99\% 1\% read/update ? read/write? 2 nodes
99\% 1\% read/update ? read/write? no mod | 2 nodes

These are the most realistic workloads for Voldemort, as a high volume read only service and about 98-99\% read to write/update.

rebalance:
Just monitor request rate during a rebalance.
Remember to somewhat record size of data set.

\begin{center}
\begin{table}[h]
	\begin{tabular}{|c|c|c|l|}
		\multicolumn{1}{c}{Test case} & 
		\multicolumn{1}{c}{read \%} & 
		\multicolumn{1}{c}{write \%} & 
		\multicolumn{1}{c}{state} \\
		\hline

		TC0 & 100 & 0 & no mod \\
		TC1 & 100 & 0 & mod \\
		TC2 & 99 & 1 & no mod \\
		TC3 & 99 & 1 & mod \\
		TC4 & 1 & 99 & no mod \\
		TC5 & 1 & 99 & mod \\

		\hline
	\end{tabular}
	\caption{Test case setup. No mod/mod is shorthand for no modification and modification, meaning whether we will be using original or our source code for this test.}
	\label{tbl:testcases}
\end{table}
\end{center}

\section{Experiences}
Networkspeed is a limitation. 
No real difference between 12MB and 2G cache. 


Findings:

Network is of the utmost importance.

Performance seem very consistent.


\input{results/figures}


\section{Experiments}
\subsection{Setup}
\subsubsection{Benchmark tool}
We use Voldemorts built in benchmark tool to send data to our cluster. This allows for varying request distribution, frequency and number of sending threads. TODO: Eivind fyll inn med scripts osv... 

\subsubsection{Hardware}
We have 4 computers involved in these experiments:
\begin{enumerate}
\item Hackintosh: Intel Core i7 2.5GHz Quad Core  16 GB Memory 250GB SSD
\item MacBook Pro: Intel Core i7 2.6 GHz Quad Core 8 GB Memory 250GB SSD
\item MacBook Pro: Intel Core i5 2.5 GHz Dual Core 8 GB Memory 120GB SSD
\item Mac Mini: Intel Core 2 Duo 2.4 GHz Dual Core 8 GB Memory 250GB SSD
\end{enumerate}

In addition we use a D-Link Dir-655 gigabit router for networking.

\subsubsection{Software}
All computers run Apple OS X 10.9.2 operating system. 

\subsection{Baseline}
In this experiment we want to establish a baseline for how a cluster behaves under load. We have both Macbooks sharing 16 partitions. We use the Hackintosh for generating traffic. This experiment was run with a request destribution of 99\% reads and 1 \% writes. We will measure overall throughput as well as how stressed each system is under the experiment.

We expect the du







